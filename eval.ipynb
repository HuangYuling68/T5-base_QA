{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59480464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# 你保存模型的位置\n",
    "model_path = \"./mengzi_t5_qa_model\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c268af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "test_data_path = \"data/dev.json\"\n",
    "test_data = []\n",
    "with open(test_data_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():  # 忽略空行\n",
    "            test_data.append(json.loads(line.strip()))\n",
    "# 构造 input_text 和 target_text\n",
    "test_samples = [\n",
    "    {\n",
    "        \"input_text\": f\"问题：{item['question']} 文本：{item['context']}\",\n",
    "        \"target_text\": item['answer']\n",
    "    }\n",
    "    for item in test_data\n",
    "]\n",
    "\n",
    "test_dataset = Dataset.from_list(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b3e1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import jieba\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "\n",
    "def preprocess_function(examples, tokenizer):\n",
    "    inputs = tokenizer(\n",
    "        examples[\"input_text\"],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        examples[\"target_text\"],\n",
    "        max_length=64,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "def preprocess_and_predict(dataset,model,tokenizer):\n",
    "    print(\"Preprocessing dataset...\")\n",
    "    tokenized_dataset=dataset.map(lambda x: preprocess_function(x, tokenizer), batched=True)\n",
    "    tokenized_dataset.set_format(type='torch')\n",
    "    print(\"Dataset preprocessing complete.\")\n",
    "    print(\"Starting prediction...\")\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    data_loader = DataLoader(tokenized_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "    for i, batch in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        input_ids = batch[\"input_ids\"].to(model.device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=64)\n",
    "        decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        batch_indices = batch[\"input_ids\"].shape[0]\n",
    "        start_idx = i * data_loader.batch_size\n",
    "        end_idx = start_idx + batch_indices\n",
    "        decoded_labels = test_dataset[start_idx:end_idx][\"target_text\"]\n",
    "\n",
    "        predictions.extend(decoded_preds)\n",
    "        references.extend([[label] for label in decoded_labels])\n",
    "    print(\"Prediction complete.\")\n",
    "    return predictions, references\n",
    "\n",
    "def evaluate_bleu(predictions, references):\n",
    "    print(\"Evaluating BLEU scores...\")\n",
    "    bleu1 = bleu2 = bleu3 = bleu4 = 0\n",
    "    smoothie = SmoothingFunction().method4\n",
    "\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        pred_tokens = list(jieba.cut(pred))  # 分词后的预测\n",
    "        ref_tokens = [list(jieba.cut(ref[0]))]  # 分词后的参考答案（必须是嵌套列表）\n",
    "\n",
    "        bleu1 += sentence_bleu(ref_tokens, pred_tokens, weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "        bleu2 += sentence_bleu(ref_tokens, pred_tokens, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie)\n",
    "        bleu3 += sentence_bleu(ref_tokens, pred_tokens, weights=(0.33, 0.33, 0.33, 0), smoothing_function=smoothie)\n",
    "        bleu4 += sentence_bleu(ref_tokens, pred_tokens, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
    "\n",
    "    total = len(predictions)\n",
    "    print(f\"BLEU-1: {bleu1 / total:.4f}\")\n",
    "    print(f\"BLEU-2: {bleu2 / total:.4f}\")\n",
    "    print(f\"BLEU-3: {bleu3 / total:.4f}\")\n",
    "    print(f\"BLEU-4: {bleu4 / total:.4f}\")\n",
    "\n",
    "def evaluation_pipline(dataset,model,tokenizer):\n",
    "    predictions, references = preprocess_and_predict(dataset,model,tokenizer)\n",
    "    evaluate_bleu(predictions, references)\n",
    "    return predictions, references\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b4ba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating trained model...\n",
      "Preprocessing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 984/984 [00:01<00:00, 937.86 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preprocessing complete.\n",
      "Starting prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492/492 [03:08<00:00,  2.61it/s]\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction complete.\n",
      "Evaluating BLEU scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.548 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.6338\n",
      "BLEU-2: 0.6027\n",
      "BLEU-3: 0.4925\n",
      "BLEU-4: 0.4057\n",
      "Question 1: 问题：2017年银行贷款基准利率 文本：年基准利率4.35%。 从实际看,贷款的基本条件是: 一是中国大陆居民,年龄在60岁以下; 二是有稳定的住址和工作或经营地点; 三是有稳定的收入来源; 四是无不良信用记录,贷款用途不能作为炒股,赌博等行为; 五是具有完全民事行为能力。\n",
      "Reference Answer 1: 年基准利率4.35%\n",
      "Model Answer 1: 4.35%\n",
      "Question 2: 问题：2017年银行贷款基准利率 文本：年基准利率4.35%。 从实际看,贷款的基本条件是: 一是中国大陆居民,年龄在60岁以下; 二是有稳定的住址和工作或经营地点; 三是有稳定的收入来源; 四是无不良信用记录,贷款用途不能作为炒股,赌博等行为; 五是具有完全民事行为能力。\n",
      "Reference Answer 2: 4.35%\n",
      "Model Answer 2: 4.35%\n",
      "Question 3: 问题：格力空调哪个系列好 文本：U系列是最好的，采用国际顶尖技术（由格力自主研发）双级变频压缩机，提高压缩机运转效率，制冷制热能力更强劲；1赫兹变频技术，使空调相当于一个15 W电灯泡，更加节能省电；送风面积广，风力大；生态风，净化空气。非常不错，现在国美在做活动，可以了解一下。\n",
      "Reference Answer 3: U系列\n",
      "Model Answer 3: U系列\n",
      "Question 4: 问题：橱柜宽度 文本：平面操作区域进深（即宽度）以40至60厘米为宜；要充分考虑洗菜盆的宽度。以标准洗菜盆来算，应选择550－－600MM的宽度为好。另：在高度方面，根据我国人体高度测算，掌握以下尺寸为宜：操作台高度在89至92厘米为宜；平面操作区域进深以40至60厘米为宜；抽油烟机与灶台的距离掌握在60至80厘米为宜；操作台上方的吊柜要能使主人操作时不碰头为宜，它距地面最小距离不应小于145厘米，进深尺寸为25至35厘米，吊柜与操作台之间的距离应在55厘米以上。\n",
      "Reference Answer 4: 以40至60厘米为宜\n",
      "Model Answer 4: 40至60厘米\n",
      "Question 5: 问题：橱柜宽度 文本：平面操作区域进深（即宽度）以40至60厘米为宜；要充分考虑洗菜盆的宽度。以标准洗菜盆来算，应选择550－－600MM的宽度为好。另：在高度方面，根据我国人体高度测算，掌握以下尺寸为宜：操作台高度在89至92厘米为宜；平面操作区域进深以40至60厘米为宜；抽油烟机与灶台的距离掌握在60至80厘米为宜；操作台上方的吊柜要能使主人操作时不碰头为宜，它距地面最小距离不应小于145厘米，进深尺寸为25至35厘米，吊柜与操作台之间的距离应在55厘米以上。\n",
      "Reference Answer 5: 40至60厘米\n",
      "Model Answer 5: 40至60厘米\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating trained model...\")\n",
    "predictions, references = evaluation_pipline(test_dataset, model, tokenizer)\n",
    "for i in range(5):\n",
    "    print(f\"Question {i+1}: {test_samples[i]['input_text']}\")\n",
    "    print(f\"Reference Answer {i+1}: {test_samples[i]['target_text']}\")\n",
    "    print(f\"Model Answer {i+1}: {predictions[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eacbee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果已保存到 qa_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"question\": [item[\"input_text\"] for item in test_samples],\n",
    "    \"reference_answer\": [ref[0] for ref in references],\n",
    "    \"predicted_answer\": predictions\n",
    "})\n",
    "\n",
    "df.to_csv(\"qa_predictions.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"预测结果已保存到 qa_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t5_base_qa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
